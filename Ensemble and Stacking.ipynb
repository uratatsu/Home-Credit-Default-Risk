{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# modeling \n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# memory management\n",
    "import gc\n",
    "\n",
    "from math import sqrt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\data\\Jupyter Notebook\\kaggle\\Home-Credit-Default-Risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理済データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train = pd.read_csv('m_train.csv')\n",
    "test = pd.read_csv('m_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['TARGET']\n",
    "train = train.drop('TARGET',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.fillna(train.median())\n",
    "x_test = test.fillna(test.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train['SK_ID_CURR']\n",
    "test_ids = test['SK_ID_CURR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_feats = ['SK_ID_CURR']\n",
    "features = [f_ for f_ in x_train.columns if f_ not in excluded_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[features]\n",
    "x_test = x_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_first = x_train\n",
    "x_test_first = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 3\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "class CatboostWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "        \n",
    "class LightGBMWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['feature_fraction_seed'] = seed\n",
    "        params['bagging_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr = x_train.loc[train_index]\n",
    "        y_tr = y_train.loc[train_index]\n",
    "        x_te = x_train.loc[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'nrounds': 200\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.5,\n",
    "    'depth': 3,\n",
    "    'l2_leaf_reg': 40,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.7,\n",
    "    'scale_pos_weight': 5,\n",
    "    'eval_metric': 'AUC',\n",
    "    'od_type': 'Iter',\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    'n_estimators':200,\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':123,\n",
    "    'colsample_bytree':0.8,\n",
    "    'subsample':0.9,\n",
    "    'max_depth':15,\n",
    "    'reg_alpha':0.1,\n",
    "    'reg_lambda':0.1,\n",
    "    'min_split_gain':0.01,\n",
    "    'min_child_weight':2    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)\n",
    "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 218ms\tremaining: 43.5s\n",
      "1:\ttotal: 435ms\tremaining: 43.1s\n",
      "2:\ttotal: 655ms\tremaining: 43s\n",
      "3:\ttotal: 871ms\tremaining: 42.7s\n",
      "4:\ttotal: 1.08s\tremaining: 42.1s\n",
      "5:\ttotal: 1.29s\tremaining: 41.7s\n",
      "6:\ttotal: 1.5s\tremaining: 41.4s\n",
      "7:\ttotal: 1.71s\tremaining: 41.1s\n",
      "8:\ttotal: 1.92s\tremaining: 40.8s\n",
      "9:\ttotal: 2.13s\tremaining: 40.5s\n",
      "10:\ttotal: 2.36s\tremaining: 40.6s\n",
      "11:\ttotal: 2.58s\tremaining: 40.4s\n",
      "12:\ttotal: 2.78s\tremaining: 40s\n",
      "13:\ttotal: 3s\tremaining: 39.9s\n",
      "14:\ttotal: 3.22s\tremaining: 39.7s\n",
      "15:\ttotal: 3.44s\tremaining: 39.6s\n",
      "16:\ttotal: 3.67s\tremaining: 39.5s\n",
      "17:\ttotal: 3.94s\tremaining: 39.8s\n",
      "18:\ttotal: 4.17s\tremaining: 39.8s\n",
      "19:\ttotal: 4.39s\tremaining: 39.5s\n",
      "20:\ttotal: 4.6s\tremaining: 39.2s\n",
      "21:\ttotal: 4.82s\tremaining: 39s\n",
      "22:\ttotal: 5.07s\tremaining: 39s\n",
      "23:\ttotal: 5.32s\tremaining: 39s\n",
      "24:\ttotal: 5.57s\tremaining: 39s\n",
      "25:\ttotal: 5.82s\tremaining: 38.9s\n",
      "26:\ttotal: 6.04s\tremaining: 38.7s\n",
      "27:\ttotal: 6.26s\tremaining: 38.5s\n",
      "28:\ttotal: 6.48s\tremaining: 38.2s\n",
      "29:\ttotal: 6.69s\tremaining: 37.9s\n",
      "30:\ttotal: 6.91s\tremaining: 37.7s\n",
      "31:\ttotal: 7.12s\tremaining: 37.4s\n",
      "32:\ttotal: 7.33s\tremaining: 37.1s\n",
      "33:\ttotal: 7.56s\tremaining: 36.9s\n",
      "34:\ttotal: 7.76s\tremaining: 36.6s\n",
      "35:\ttotal: 7.97s\tremaining: 36.3s\n",
      "36:\ttotal: 8.18s\tremaining: 36s\n",
      "37:\ttotal: 8.38s\tremaining: 35.7s\n",
      "38:\ttotal: 8.6s\tremaining: 35.5s\n",
      "39:\ttotal: 8.82s\tremaining: 35.3s\n",
      "40:\ttotal: 9.04s\tremaining: 35.1s\n",
      "41:\ttotal: 9.27s\tremaining: 34.9s\n",
      "42:\ttotal: 9.5s\tremaining: 34.7s\n",
      "43:\ttotal: 9.74s\tremaining: 34.5s\n",
      "44:\ttotal: 9.97s\tremaining: 34.3s\n",
      "45:\ttotal: 10.2s\tremaining: 34.1s\n",
      "46:\ttotal: 10.4s\tremaining: 33.9s\n",
      "47:\ttotal: 10.6s\tremaining: 33.6s\n",
      "48:\ttotal: 10.9s\tremaining: 33.5s\n",
      "49:\ttotal: 11.1s\tremaining: 33.4s\n",
      "50:\ttotal: 11.4s\tremaining: 33.2s\n",
      "51:\ttotal: 11.6s\tremaining: 33s\n",
      "52:\ttotal: 11.8s\tremaining: 32.8s\n",
      "53:\ttotal: 12s\tremaining: 32.5s\n",
      "54:\ttotal: 12.3s\tremaining: 32.3s\n",
      "55:\ttotal: 12.5s\tremaining: 32.1s\n",
      "56:\ttotal: 12.7s\tremaining: 31.9s\n",
      "57:\ttotal: 13s\tremaining: 31.7s\n",
      "58:\ttotal: 13.2s\tremaining: 31.6s\n",
      "59:\ttotal: 13.5s\tremaining: 31.4s\n",
      "60:\ttotal: 13.8s\tremaining: 31.4s\n",
      "61:\ttotal: 14s\tremaining: 31.2s\n",
      "62:\ttotal: 14.2s\tremaining: 31s\n",
      "63:\ttotal: 14.5s\tremaining: 30.7s\n",
      "64:\ttotal: 14.7s\tremaining: 30.5s\n",
      "65:\ttotal: 14.9s\tremaining: 30.2s\n",
      "66:\ttotal: 15.1s\tremaining: 30s\n",
      "67:\ttotal: 15.3s\tremaining: 29.8s\n",
      "68:\ttotal: 15.6s\tremaining: 29.6s\n",
      "69:\ttotal: 15.8s\tremaining: 29.4s\n",
      "70:\ttotal: 16s\tremaining: 29.1s\n",
      "71:\ttotal: 16.2s\tremaining: 28.9s\n",
      "72:\ttotal: 16.5s\tremaining: 28.7s\n",
      "73:\ttotal: 16.7s\tremaining: 28.5s\n",
      "74:\ttotal: 17s\tremaining: 28.3s\n",
      "75:\ttotal: 17.2s\tremaining: 28.1s\n",
      "76:\ttotal: 17.4s\tremaining: 27.9s\n",
      "77:\ttotal: 17.7s\tremaining: 27.6s\n",
      "78:\ttotal: 17.9s\tremaining: 27.4s\n",
      "79:\ttotal: 18.1s\tremaining: 27.2s\n",
      "80:\ttotal: 18.3s\tremaining: 26.9s\n",
      "81:\ttotal: 18.6s\tremaining: 26.7s\n",
      "82:\ttotal: 18.8s\tremaining: 26.5s\n",
      "83:\ttotal: 19s\tremaining: 26.2s\n",
      "84:\ttotal: 19.2s\tremaining: 26s\n",
      "85:\ttotal: 19.5s\tremaining: 25.8s\n",
      "86:\ttotal: 19.7s\tremaining: 25.6s\n",
      "87:\ttotal: 19.9s\tremaining: 25.4s\n",
      "88:\ttotal: 20.2s\tremaining: 25.1s\n",
      "89:\ttotal: 20.4s\tremaining: 24.9s\n",
      "90:\ttotal: 20.6s\tremaining: 24.7s\n",
      "91:\ttotal: 20.8s\tremaining: 24.5s\n",
      "92:\ttotal: 21.1s\tremaining: 24.3s\n",
      "93:\ttotal: 21.3s\tremaining: 24.1s\n",
      "94:\ttotal: 21.6s\tremaining: 23.8s\n",
      "95:\ttotal: 21.8s\tremaining: 23.6s\n",
      "96:\ttotal: 22s\tremaining: 23.4s\n",
      "97:\ttotal: 22.3s\tremaining: 23.2s\n",
      "98:\ttotal: 22.5s\tremaining: 23s\n",
      "99:\ttotal: 22.8s\tremaining: 22.8s\n",
      "100:\ttotal: 23s\tremaining: 22.6s\n",
      "101:\ttotal: 23.2s\tremaining: 22.3s\n",
      "102:\ttotal: 23.4s\tremaining: 22.1s\n",
      "103:\ttotal: 23.7s\tremaining: 21.8s\n",
      "104:\ttotal: 23.9s\tremaining: 21.6s\n",
      "105:\ttotal: 24.1s\tremaining: 21.4s\n",
      "106:\ttotal: 24.3s\tremaining: 21.1s\n",
      "107:\ttotal: 24.5s\tremaining: 20.9s\n",
      "108:\ttotal: 24.8s\tremaining: 20.7s\n",
      "109:\ttotal: 25s\tremaining: 20.5s\n",
      "110:\ttotal: 25.2s\tremaining: 20.2s\n",
      "111:\ttotal: 25.4s\tremaining: 20s\n",
      "112:\ttotal: 25.7s\tremaining: 19.8s\n",
      "113:\ttotal: 25.9s\tremaining: 19.5s\n",
      "114:\ttotal: 26.1s\tremaining: 19.3s\n",
      "115:\ttotal: 26.4s\tremaining: 19.1s\n",
      "116:\ttotal: 26.6s\tremaining: 18.9s\n",
      "117:\ttotal: 26.8s\tremaining: 18.6s\n",
      "118:\ttotal: 27.1s\tremaining: 18.4s\n",
      "119:\ttotal: 27.3s\tremaining: 18.2s\n",
      "120:\ttotal: 27.5s\tremaining: 18s\n",
      "121:\ttotal: 27.7s\tremaining: 17.7s\n",
      "122:\ttotal: 28s\tremaining: 17.5s\n",
      "123:\ttotal: 28.2s\tremaining: 17.3s\n",
      "124:\ttotal: 28.5s\tremaining: 17.1s\n",
      "125:\ttotal: 28.7s\tremaining: 16.9s\n",
      "126:\ttotal: 29s\tremaining: 16.7s\n",
      "127:\ttotal: 29.3s\tremaining: 16.5s\n",
      "128:\ttotal: 29.5s\tremaining: 16.2s\n",
      "129:\ttotal: 29.8s\tremaining: 16s\n",
      "130:\ttotal: 30s\tremaining: 15.8s\n",
      "131:\ttotal: 30.3s\tremaining: 15.6s\n",
      "132:\ttotal: 30.5s\tremaining: 15.4s\n",
      "133:\ttotal: 30.7s\tremaining: 15.1s\n",
      "134:\ttotal: 30.9s\tremaining: 14.9s\n",
      "135:\ttotal: 31.1s\tremaining: 14.6s\n",
      "136:\ttotal: 31.3s\tremaining: 14.4s\n",
      "137:\ttotal: 31.6s\tremaining: 14.2s\n",
      "138:\ttotal: 31.8s\tremaining: 13.9s\n",
      "139:\ttotal: 32s\tremaining: 13.7s\n",
      "140:\ttotal: 32.3s\tremaining: 13.5s\n",
      "141:\ttotal: 32.5s\tremaining: 13.3s\n",
      "142:\ttotal: 32.7s\tremaining: 13s\n",
      "143:\ttotal: 32.9s\tremaining: 12.8s\n",
      "144:\ttotal: 33.1s\tremaining: 12.6s\n",
      "145:\ttotal: 33.4s\tremaining: 12.3s\n",
      "146:\ttotal: 33.6s\tremaining: 12.1s\n",
      "147:\ttotal: 33.8s\tremaining: 11.9s\n",
      "148:\ttotal: 34.1s\tremaining: 11.7s\n",
      "149:\ttotal: 34.3s\tremaining: 11.4s\n",
      "150:\ttotal: 34.6s\tremaining: 11.2s\n",
      "151:\ttotal: 34.8s\tremaining: 11s\n",
      "152:\ttotal: 35s\tremaining: 10.7s\n",
      "153:\ttotal: 35.2s\tremaining: 10.5s\n",
      "154:\ttotal: 35.5s\tremaining: 10.3s\n",
      "155:\ttotal: 35.7s\tremaining: 10.1s\n",
      "156:\ttotal: 35.9s\tremaining: 9.84s\n",
      "157:\ttotal: 36.1s\tremaining: 9.6s\n",
      "158:\ttotal: 36.4s\tremaining: 9.37s\n",
      "159:\ttotal: 36.6s\tremaining: 9.14s\n",
      "160:\ttotal: 36.8s\tremaining: 8.91s\n",
      "161:\ttotal: 37s\tremaining: 8.68s\n",
      "162:\ttotal: 37.2s\tremaining: 8.45s\n",
      "163:\ttotal: 37.5s\tremaining: 8.22s\n",
      "164:\ttotal: 37.7s\tremaining: 8s\n",
      "165:\ttotal: 38s\tremaining: 7.77s\n",
      "166:\ttotal: 38.2s\tremaining: 7.54s\n",
      "167:\ttotal: 38.4s\tremaining: 7.32s\n",
      "168:\ttotal: 38.6s\tremaining: 7.08s\n",
      "169:\ttotal: 38.8s\tremaining: 6.85s\n",
      "170:\ttotal: 39.1s\tremaining: 6.63s\n",
      "171:\ttotal: 39.3s\tremaining: 6.4s\n",
      "172:\ttotal: 39.6s\tremaining: 6.18s\n",
      "173:\ttotal: 39.8s\tremaining: 5.95s\n",
      "174:\ttotal: 40.1s\tremaining: 5.72s\n",
      "175:\ttotal: 40.3s\tremaining: 5.49s\n",
      "176:\ttotal: 40.5s\tremaining: 5.26s\n",
      "177:\ttotal: 40.7s\tremaining: 5.03s\n",
      "178:\ttotal: 40.9s\tremaining: 4.8s\n",
      "179:\ttotal: 41.2s\tremaining: 4.57s\n",
      "180:\ttotal: 41.4s\tremaining: 4.34s\n",
      "181:\ttotal: 41.6s\tremaining: 4.12s\n",
      "182:\ttotal: 41.8s\tremaining: 3.88s\n",
      "183:\ttotal: 42s\tremaining: 3.65s\n",
      "184:\ttotal: 42.3s\tremaining: 3.43s\n",
      "185:\ttotal: 42.5s\tremaining: 3.2s\n",
      "186:\ttotal: 42.7s\tremaining: 2.97s\n",
      "187:\ttotal: 42.9s\tremaining: 2.74s\n",
      "188:\ttotal: 43.2s\tremaining: 2.51s\n",
      "189:\ttotal: 43.4s\tremaining: 2.28s\n",
      "190:\ttotal: 43.6s\tremaining: 2.05s\n",
      "191:\ttotal: 43.9s\tremaining: 1.83s\n",
      "192:\ttotal: 44.1s\tremaining: 1.6s\n",
      "193:\ttotal: 44.3s\tremaining: 1.37s\n",
      "194:\ttotal: 44.5s\tremaining: 1.14s\n",
      "195:\ttotal: 44.8s\tremaining: 914ms\n",
      "196:\ttotal: 45s\tremaining: 686ms\n",
      "197:\ttotal: 45.3s\tremaining: 458ms\n",
      "198:\ttotal: 45.6s\tremaining: 229ms\n",
      "199:\ttotal: 45.9s\tremaining: 0us\n",
      "0:\ttotal: 202ms\tremaining: 40.2s\n",
      "1:\ttotal: 428ms\tremaining: 42.4s\n",
      "2:\ttotal: 654ms\tremaining: 42.9s\n",
      "3:\ttotal: 884ms\tremaining: 43.3s\n",
      "4:\ttotal: 1.13s\tremaining: 43.9s\n",
      "5:\ttotal: 1.33s\tremaining: 43.1s\n",
      "6:\ttotal: 1.54s\tremaining: 42.5s\n",
      "7:\ttotal: 1.76s\tremaining: 42.2s\n",
      "8:\ttotal: 1.98s\tremaining: 42s\n",
      "9:\ttotal: 2.22s\tremaining: 42.2s\n",
      "10:\ttotal: 2.46s\tremaining: 42.4s\n",
      "11:\ttotal: 2.69s\tremaining: 42.1s\n",
      "12:\ttotal: 2.92s\tremaining: 41.9s\n",
      "13:\ttotal: 3.13s\tremaining: 41.6s\n",
      "14:\ttotal: 3.35s\tremaining: 41.3s\n",
      "15:\ttotal: 3.56s\tremaining: 41s\n",
      "16:\ttotal: 3.77s\tremaining: 40.6s\n",
      "17:\ttotal: 3.99s\tremaining: 40.3s\n",
      "18:\ttotal: 4.2s\tremaining: 40s\n",
      "19:\ttotal: 4.42s\tremaining: 39.8s\n",
      "20:\ttotal: 4.63s\tremaining: 39.4s\n",
      "21:\ttotal: 4.85s\tremaining: 39.3s\n",
      "22:\ttotal: 5.07s\tremaining: 39s\n",
      "23:\ttotal: 5.29s\tremaining: 38.8s\n",
      "24:\ttotal: 5.5s\tremaining: 38.5s\n",
      "25:\ttotal: 5.71s\tremaining: 38.2s\n",
      "26:\ttotal: 5.93s\tremaining: 38s\n",
      "27:\ttotal: 6.15s\tremaining: 37.8s\n",
      "28:\ttotal: 6.37s\tremaining: 37.6s\n",
      "29:\ttotal: 6.6s\tremaining: 37.4s\n",
      "30:\ttotal: 6.84s\tremaining: 37.3s\n",
      "31:\ttotal: 7.07s\tremaining: 37.1s\n",
      "32:\ttotal: 7.28s\tremaining: 36.8s\n",
      "33:\ttotal: 7.5s\tremaining: 36.6s\n",
      "34:\ttotal: 7.75s\tremaining: 36.6s\n",
      "35:\ttotal: 7.98s\tremaining: 36.4s\n",
      "36:\ttotal: 8.23s\tremaining: 36.3s\n",
      "37:\ttotal: 8.47s\tremaining: 36.1s\n",
      "38:\ttotal: 8.68s\tremaining: 35.8s\n",
      "39:\ttotal: 8.9s\tremaining: 35.6s\n",
      "40:\ttotal: 9.13s\tremaining: 35.4s\n",
      "41:\ttotal: 9.35s\tremaining: 35.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42:\ttotal: 9.56s\tremaining: 34.9s\n",
      "43:\ttotal: 9.79s\tremaining: 34.7s\n",
      "44:\ttotal: 10s\tremaining: 34.4s\n",
      "45:\ttotal: 10.2s\tremaining: 34.2s\n",
      "46:\ttotal: 10.4s\tremaining: 33.9s\n",
      "47:\ttotal: 10.6s\tremaining: 33.7s\n",
      "48:\ttotal: 10.9s\tremaining: 33.5s\n",
      "49:\ttotal: 11.1s\tremaining: 33.3s\n",
      "50:\ttotal: 11.3s\tremaining: 33s\n",
      "51:\ttotal: 11.5s\tremaining: 32.8s\n",
      "52:\ttotal: 11.7s\tremaining: 32.6s\n",
      "53:\ttotal: 12s\tremaining: 32.4s\n",
      "54:\ttotal: 12.2s\tremaining: 32.3s\n",
      "55:\ttotal: 12.5s\tremaining: 32.2s\n",
      "56:\ttotal: 12.8s\tremaining: 32.1s\n",
      "57:\ttotal: 13.1s\tremaining: 32s\n",
      "58:\ttotal: 13.3s\tremaining: 31.8s\n",
      "59:\ttotal: 13.6s\tremaining: 31.7s\n",
      "60:\ttotal: 13.8s\tremaining: 31.5s\n",
      "61:\ttotal: 14.1s\tremaining: 31.3s\n",
      "62:\ttotal: 14.3s\tremaining: 31.1s\n",
      "63:\ttotal: 14.5s\tremaining: 30.8s\n",
      "64:\ttotal: 14.7s\tremaining: 30.6s\n",
      "65:\ttotal: 15s\tremaining: 30.4s\n",
      "66:\ttotal: 15.2s\tremaining: 30.1s\n",
      "67:\ttotal: 15.4s\tremaining: 29.9s\n",
      "68:\ttotal: 15.6s\tremaining: 29.7s\n",
      "69:\ttotal: 15.8s\tremaining: 29.4s\n",
      "70:\ttotal: 16.1s\tremaining: 29.2s\n",
      "71:\ttotal: 16.3s\tremaining: 28.9s\n",
      "72:\ttotal: 16.5s\tremaining: 28.7s\n",
      "73:\ttotal: 16.7s\tremaining: 28.5s\n",
      "74:\ttotal: 16.9s\tremaining: 28.2s\n",
      "75:\ttotal: 17.2s\tremaining: 28s\n",
      "76:\ttotal: 17.4s\tremaining: 27.7s\n",
      "77:\ttotal: 17.6s\tremaining: 27.5s\n",
      "78:\ttotal: 17.8s\tremaining: 27.3s\n",
      "79:\ttotal: 18.1s\tremaining: 27.1s\n",
      "80:\ttotal: 18.3s\tremaining: 26.9s\n",
      "81:\ttotal: 18.5s\tremaining: 26.6s\n",
      "82:\ttotal: 18.7s\tremaining: 26.4s\n",
      "83:\ttotal: 18.9s\tremaining: 26.1s\n",
      "84:\ttotal: 19.2s\tremaining: 25.9s\n",
      "85:\ttotal: 19.4s\tremaining: 25.7s\n",
      "86:\ttotal: 19.7s\tremaining: 25.6s\n",
      "87:\ttotal: 19.9s\tremaining: 25.3s\n",
      "88:\ttotal: 20.1s\tremaining: 25.1s\n",
      "89:\ttotal: 20.3s\tremaining: 24.9s\n",
      "90:\ttotal: 20.6s\tremaining: 24.6s\n",
      "91:\ttotal: 20.8s\tremaining: 24.4s\n",
      "92:\ttotal: 21s\tremaining: 24.2s\n",
      "93:\ttotal: 21.2s\tremaining: 23.9s\n",
      "94:\ttotal: 21.5s\tremaining: 23.7s\n",
      "95:\ttotal: 21.7s\tremaining: 23.5s\n",
      "96:\ttotal: 21.9s\tremaining: 23.2s\n",
      "97:\ttotal: 22.1s\tremaining: 23s\n",
      "98:\ttotal: 22.3s\tremaining: 22.8s\n",
      "99:\ttotal: 22.5s\tremaining: 22.5s\n",
      "100:\ttotal: 22.8s\tremaining: 22.3s\n",
      "101:\ttotal: 23s\tremaining: 22.1s\n",
      "102:\ttotal: 23.2s\tremaining: 21.8s\n",
      "103:\ttotal: 23.4s\tremaining: 21.6s\n",
      "104:\ttotal: 23.7s\tremaining: 21.4s\n",
      "105:\ttotal: 23.9s\tremaining: 21.2s\n",
      "106:\ttotal: 24.1s\tremaining: 21s\n",
      "107:\ttotal: 24.3s\tremaining: 20.7s\n",
      "108:\ttotal: 24.5s\tremaining: 20.5s\n",
      "109:\ttotal: 24.7s\tremaining: 20.2s\n",
      "110:\ttotal: 25s\tremaining: 20s\n",
      "111:\ttotal: 25.2s\tremaining: 19.8s\n",
      "112:\ttotal: 25.5s\tremaining: 19.6s\n",
      "113:\ttotal: 25.7s\tremaining: 19.4s\n",
      "114:\ttotal: 25.9s\tremaining: 19.2s\n",
      "115:\ttotal: 26.2s\tremaining: 18.9s\n",
      "116:\ttotal: 26.4s\tremaining: 18.7s\n",
      "117:\ttotal: 26.6s\tremaining: 18.5s\n",
      "118:\ttotal: 26.8s\tremaining: 18.3s\n",
      "119:\ttotal: 27s\tremaining: 18s\n",
      "120:\ttotal: 27.3s\tremaining: 17.8s\n",
      "121:\ttotal: 27.5s\tremaining: 17.6s\n",
      "122:\ttotal: 27.7s\tremaining: 17.3s\n",
      "123:\ttotal: 27.9s\tremaining: 17.1s\n",
      "124:\ttotal: 28.2s\tremaining: 16.9s\n",
      "125:\ttotal: 28.4s\tremaining: 16.7s\n",
      "126:\ttotal: 28.7s\tremaining: 16.5s\n",
      "127:\ttotal: 29s\tremaining: 16.3s\n",
      "128:\ttotal: 29.2s\tremaining: 16.1s\n",
      "129:\ttotal: 29.5s\tremaining: 15.9s\n",
      "130:\ttotal: 29.7s\tremaining: 15.6s\n",
      "131:\ttotal: 29.9s\tremaining: 15.4s\n",
      "132:\ttotal: 30.1s\tremaining: 15.2s\n",
      "133:\ttotal: 30.4s\tremaining: 14.9s\n",
      "134:\ttotal: 30.6s\tremaining: 14.7s\n",
      "135:\ttotal: 30.8s\tremaining: 14.5s\n",
      "136:\ttotal: 31.1s\tremaining: 14.3s\n",
      "137:\ttotal: 31.3s\tremaining: 14.1s\n",
      "138:\ttotal: 31.5s\tremaining: 13.8s\n",
      "139:\ttotal: 31.7s\tremaining: 13.6s\n",
      "140:\ttotal: 32s\tremaining: 13.4s\n",
      "141:\ttotal: 32.2s\tremaining: 13.1s\n",
      "142:\ttotal: 32.4s\tremaining: 12.9s\n",
      "143:\ttotal: 32.6s\tremaining: 12.7s\n",
      "144:\ttotal: 32.8s\tremaining: 12.5s\n",
      "145:\ttotal: 33.1s\tremaining: 12.2s\n",
      "146:\ttotal: 33.3s\tremaining: 12s\n",
      "147:\ttotal: 33.5s\tremaining: 11.8s\n",
      "148:\ttotal: 33.7s\tremaining: 11.5s\n",
      "149:\ttotal: 33.9s\tremaining: 11.3s\n",
      "150:\ttotal: 34.1s\tremaining: 11.1s\n",
      "151:\ttotal: 34.3s\tremaining: 10.8s\n",
      "152:\ttotal: 34.6s\tremaining: 10.6s\n",
      "153:\ttotal: 34.8s\tremaining: 10.4s\n",
      "154:\ttotal: 35s\tremaining: 10.2s\n",
      "155:\ttotal: 35.3s\tremaining: 9.95s\n",
      "156:\ttotal: 35.5s\tremaining: 9.72s\n",
      "157:\ttotal: 35.7s\tremaining: 9.49s\n",
      "158:\ttotal: 35.9s\tremaining: 9.26s\n",
      "159:\ttotal: 36.1s\tremaining: 9.04s\n",
      "160:\ttotal: 36.4s\tremaining: 8.81s\n",
      "161:\ttotal: 36.6s\tremaining: 8.59s\n",
      "162:\ttotal: 36.9s\tremaining: 8.37s\n",
      "163:\ttotal: 37.1s\tremaining: 8.15s\n",
      "164:\ttotal: 37.3s\tremaining: 7.92s\n",
      "165:\ttotal: 37.5s\tremaining: 7.69s\n",
      "166:\ttotal: 37.8s\tremaining: 7.46s\n",
      "167:\ttotal: 38s\tremaining: 7.24s\n",
      "168:\ttotal: 38.2s\tremaining: 7.01s\n",
      "169:\ttotal: 38.4s\tremaining: 6.78s\n",
      "170:\ttotal: 38.6s\tremaining: 6.55s\n",
      "171:\ttotal: 38.9s\tremaining: 6.32s\n",
      "172:\ttotal: 39.1s\tremaining: 6.1s\n",
      "173:\ttotal: 39.3s\tremaining: 5.87s\n",
      "174:\ttotal: 39.5s\tremaining: 5.64s\n",
      "175:\ttotal: 39.7s\tremaining: 5.42s\n",
      "176:\ttotal: 39.9s\tremaining: 5.19s\n",
      "177:\ttotal: 40.2s\tremaining: 4.96s\n",
      "178:\ttotal: 40.4s\tremaining: 4.74s\n",
      "179:\ttotal: 40.7s\tremaining: 4.52s\n",
      "180:\ttotal: 40.9s\tremaining: 4.29s\n",
      "181:\ttotal: 41.1s\tremaining: 4.07s\n",
      "182:\ttotal: 41.3s\tremaining: 3.84s\n",
      "183:\ttotal: 41.5s\tremaining: 3.61s\n",
      "184:\ttotal: 41.8s\tremaining: 3.38s\n",
      "185:\ttotal: 42s\tremaining: 3.16s\n",
      "186:\ttotal: 42.2s\tremaining: 2.93s\n",
      "187:\ttotal: 42.5s\tremaining: 2.71s\n",
      "188:\ttotal: 42.7s\tremaining: 2.49s\n",
      "189:\ttotal: 42.9s\tremaining: 2.26s\n",
      "190:\ttotal: 43.2s\tremaining: 2.03s\n",
      "191:\ttotal: 43.4s\tremaining: 1.81s\n",
      "192:\ttotal: 43.6s\tremaining: 1.58s\n",
      "193:\ttotal: 43.8s\tremaining: 1.35s\n",
      "194:\ttotal: 44s\tremaining: 1.13s\n",
      "195:\ttotal: 44.3s\tremaining: 904ms\n",
      "196:\ttotal: 44.5s\tremaining: 678ms\n",
      "197:\ttotal: 44.8s\tremaining: 452ms\n",
      "198:\ttotal: 45.1s\tremaining: 226ms\n",
      "199:\ttotal: 45.3s\tremaining: 0us\n",
      "0:\ttotal: 206ms\tremaining: 41.1s\n",
      "1:\ttotal: 429ms\tremaining: 42.5s\n",
      "2:\ttotal: 638ms\tremaining: 41.9s\n",
      "3:\ttotal: 853ms\tremaining: 41.8s\n",
      "4:\ttotal: 1.07s\tremaining: 41.6s\n",
      "5:\ttotal: 1.28s\tremaining: 41.3s\n",
      "6:\ttotal: 1.48s\tremaining: 40.8s\n",
      "7:\ttotal: 1.68s\tremaining: 40.4s\n",
      "8:\ttotal: 1.9s\tremaining: 40.4s\n",
      "9:\ttotal: 2.11s\tremaining: 40.2s\n",
      "10:\ttotal: 2.33s\tremaining: 40.1s\n",
      "11:\ttotal: 2.58s\tremaining: 40.4s\n",
      "12:\ttotal: 2.81s\tremaining: 40.5s\n",
      "13:\ttotal: 3.02s\tremaining: 40.1s\n",
      "14:\ttotal: 3.23s\tremaining: 39.9s\n",
      "15:\ttotal: 3.44s\tremaining: 39.6s\n",
      "16:\ttotal: 3.66s\tremaining: 39.4s\n",
      "17:\ttotal: 3.88s\tremaining: 39.2s\n",
      "18:\ttotal: 4.08s\tremaining: 38.9s\n",
      "19:\ttotal: 4.29s\tremaining: 38.6s\n",
      "20:\ttotal: 4.52s\tremaining: 38.5s\n",
      "21:\ttotal: 4.74s\tremaining: 38.4s\n",
      "22:\ttotal: 4.97s\tremaining: 38.3s\n",
      "23:\ttotal: 5.21s\tremaining: 38.2s\n",
      "24:\ttotal: 5.47s\tremaining: 38.3s\n",
      "25:\ttotal: 5.71s\tremaining: 38.2s\n",
      "26:\ttotal: 5.93s\tremaining: 38s\n",
      "27:\ttotal: 6.15s\tremaining: 37.8s\n",
      "28:\ttotal: 6.37s\tremaining: 37.5s\n",
      "29:\ttotal: 6.59s\tremaining: 37.3s\n",
      "30:\ttotal: 6.82s\tremaining: 37.2s\n",
      "31:\ttotal: 7.03s\tremaining: 36.9s\n",
      "32:\ttotal: 7.24s\tremaining: 36.6s\n",
      "33:\ttotal: 7.46s\tremaining: 36.4s\n",
      "34:\ttotal: 7.67s\tremaining: 36.2s\n",
      "35:\ttotal: 7.9s\tremaining: 36s\n",
      "36:\ttotal: 8.14s\tremaining: 35.8s\n",
      "37:\ttotal: 8.38s\tremaining: 35.8s\n",
      "38:\ttotal: 8.61s\tremaining: 35.5s\n",
      "39:\ttotal: 8.82s\tremaining: 35.3s\n",
      "40:\ttotal: 9.04s\tremaining: 35.1s\n",
      "41:\ttotal: 9.26s\tremaining: 34.9s\n",
      "42:\ttotal: 9.48s\tremaining: 34.6s\n",
      "43:\ttotal: 9.7s\tremaining: 34.4s\n",
      "44:\ttotal: 9.91s\tremaining: 34.1s\n",
      "45:\ttotal: 10.1s\tremaining: 33.9s\n",
      "46:\ttotal: 10.3s\tremaining: 33.7s\n",
      "47:\ttotal: 10.6s\tremaining: 33.5s\n",
      "48:\ttotal: 10.8s\tremaining: 33.4s\n",
      "49:\ttotal: 11.1s\tremaining: 33.2s\n",
      "50:\ttotal: 11.3s\tremaining: 33.1s\n",
      "51:\ttotal: 11.5s\tremaining: 32.8s\n",
      "52:\ttotal: 11.8s\tremaining: 32.7s\n",
      "53:\ttotal: 12.1s\tremaining: 32.6s\n",
      "54:\ttotal: 12.3s\tremaining: 32.5s\n",
      "55:\ttotal: 12.6s\tremaining: 32.4s\n",
      "56:\ttotal: 12.8s\tremaining: 32.2s\n",
      "57:\ttotal: 13.1s\tremaining: 32s\n",
      "58:\ttotal: 13.3s\tremaining: 31.8s\n",
      "59:\ttotal: 13.5s\tremaining: 31.5s\n",
      "60:\ttotal: 13.8s\tremaining: 31.3s\n",
      "61:\ttotal: 14s\tremaining: 31.1s\n",
      "62:\ttotal: 14.2s\tremaining: 30.9s\n",
      "63:\ttotal: 14.4s\tremaining: 30.7s\n",
      "64:\ttotal: 14.7s\tremaining: 30.5s\n",
      "65:\ttotal: 14.9s\tremaining: 30.2s\n",
      "66:\ttotal: 15.1s\tremaining: 30s\n",
      "67:\ttotal: 15.3s\tremaining: 29.8s\n",
      "68:\ttotal: 15.5s\tremaining: 29.5s\n",
      "69:\ttotal: 15.8s\tremaining: 29.3s\n",
      "70:\ttotal: 16s\tremaining: 29s\n",
      "71:\ttotal: 16.2s\tremaining: 28.8s\n",
      "72:\ttotal: 16.4s\tremaining: 28.6s\n",
      "73:\ttotal: 16.7s\tremaining: 28.4s\n",
      "74:\ttotal: 16.9s\tremaining: 28.2s\n",
      "75:\ttotal: 17.2s\tremaining: 28s\n",
      "76:\ttotal: 17.4s\tremaining: 27.8s\n",
      "77:\ttotal: 17.6s\tremaining: 27.5s\n",
      "78:\ttotal: 17.8s\tremaining: 27.3s\n",
      "79:\ttotal: 18s\tremaining: 27.1s\n",
      "80:\ttotal: 18.3s\tremaining: 26.8s\n",
      "81:\ttotal: 18.5s\tremaining: 26.6s\n",
      "82:\ttotal: 18.7s\tremaining: 26.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83:\ttotal: 18.9s\tremaining: 26.1s\n",
      "84:\ttotal: 19.1s\tremaining: 25.9s\n",
      "85:\ttotal: 19.4s\tremaining: 25.7s\n",
      "86:\ttotal: 19.6s\tremaining: 25.4s\n",
      "87:\ttotal: 19.8s\tremaining: 25.2s\n",
      "88:\ttotal: 20s\tremaining: 25s\n",
      "89:\ttotal: 20.3s\tremaining: 24.8s\n",
      "90:\ttotal: 20.5s\tremaining: 24.6s\n",
      "91:\ttotal: 20.7s\tremaining: 24.3s\n",
      "92:\ttotal: 20.9s\tremaining: 24.1s\n",
      "93:\ttotal: 21.1s\tremaining: 23.8s\n",
      "94:\ttotal: 21.3s\tremaining: 23.6s\n",
      "95:\ttotal: 21.6s\tremaining: 23.3s\n",
      "96:\ttotal: 21.8s\tremaining: 23.1s\n",
      "97:\ttotal: 22s\tremaining: 22.9s\n",
      "98:\ttotal: 22.2s\tremaining: 22.7s\n",
      "99:\ttotal: 22.5s\tremaining: 22.5s\n",
      "100:\ttotal: 22.8s\tremaining: 22.3s\n",
      "101:\ttotal: 23s\tremaining: 22.1s\n",
      "102:\ttotal: 23.2s\tremaining: 21.8s\n",
      "103:\ttotal: 23.4s\tremaining: 21.6s\n",
      "104:\ttotal: 23.6s\tremaining: 21.4s\n",
      "105:\ttotal: 23.8s\tremaining: 21.1s\n",
      "106:\ttotal: 24.1s\tremaining: 20.9s\n",
      "107:\ttotal: 24.3s\tremaining: 20.7s\n",
      "108:\ttotal: 24.5s\tremaining: 20.5s\n",
      "109:\ttotal: 24.7s\tremaining: 20.2s\n",
      "110:\ttotal: 25s\tremaining: 20s\n",
      "111:\ttotal: 25.2s\tremaining: 19.8s\n",
      "112:\ttotal: 25.4s\tremaining: 19.6s\n",
      "113:\ttotal: 25.6s\tremaining: 19.3s\n",
      "114:\ttotal: 25.8s\tremaining: 19.1s\n",
      "115:\ttotal: 26.1s\tremaining: 18.9s\n",
      "116:\ttotal: 26.3s\tremaining: 18.6s\n",
      "117:\ttotal: 26.5s\tremaining: 18.4s\n",
      "118:\ttotal: 26.7s\tremaining: 18.2s\n",
      "119:\ttotal: 26.9s\tremaining: 18s\n",
      "120:\ttotal: 27.1s\tremaining: 17.7s\n",
      "121:\ttotal: 27.4s\tremaining: 17.5s\n",
      "122:\ttotal: 27.6s\tremaining: 17.3s\n",
      "123:\ttotal: 27.8s\tremaining: 17.1s\n",
      "124:\ttotal: 28.1s\tremaining: 16.9s\n",
      "125:\ttotal: 28.4s\tremaining: 16.7s\n",
      "126:\ttotal: 28.7s\tremaining: 16.5s\n",
      "127:\ttotal: 28.9s\tremaining: 16.3s\n",
      "128:\ttotal: 29.2s\tremaining: 16.1s\n",
      "129:\ttotal: 29.4s\tremaining: 15.8s\n",
      "130:\ttotal: 29.6s\tremaining: 15.6s\n",
      "131:\ttotal: 29.8s\tremaining: 15.4s\n",
      "132:\ttotal: 30s\tremaining: 15.1s\n",
      "133:\ttotal: 30.3s\tremaining: 14.9s\n",
      "134:\ttotal: 30.5s\tremaining: 14.7s\n",
      "135:\ttotal: 30.7s\tremaining: 14.5s\n",
      "136:\ttotal: 31s\tremaining: 14.2s\n",
      "137:\ttotal: 31.2s\tremaining: 14s\n",
      "138:\ttotal: 31.4s\tremaining: 13.8s\n",
      "139:\ttotal: 31.6s\tremaining: 13.6s\n",
      "140:\ttotal: 31.9s\tremaining: 13.3s\n",
      "141:\ttotal: 32.1s\tremaining: 13.1s\n",
      "142:\ttotal: 32.3s\tremaining: 12.9s\n",
      "143:\ttotal: 32.5s\tremaining: 12.6s\n",
      "144:\ttotal: 32.7s\tremaining: 12.4s\n",
      "145:\ttotal: 33s\tremaining: 12.2s\n",
      "146:\ttotal: 33.2s\tremaining: 12s\n",
      "147:\ttotal: 33.4s\tremaining: 11.7s\n",
      "148:\ttotal: 33.6s\tremaining: 11.5s\n",
      "149:\ttotal: 33.8s\tremaining: 11.3s\n",
      "150:\ttotal: 34.1s\tremaining: 11.1s\n",
      "151:\ttotal: 34.3s\tremaining: 10.8s\n",
      "152:\ttotal: 34.6s\tremaining: 10.6s\n",
      "153:\ttotal: 34.8s\tremaining: 10.4s\n",
      "154:\ttotal: 35s\tremaining: 10.2s\n",
      "155:\ttotal: 35.2s\tremaining: 9.94s\n",
      "156:\ttotal: 35.5s\tremaining: 9.71s\n",
      "157:\ttotal: 35.7s\tremaining: 9.48s\n",
      "158:\ttotal: 35.9s\tremaining: 9.25s\n",
      "159:\ttotal: 36.1s\tremaining: 9.03s\n",
      "160:\ttotal: 36.4s\tremaining: 8.8s\n",
      "161:\ttotal: 36.6s\tremaining: 8.58s\n",
      "162:\ttotal: 36.8s\tremaining: 8.36s\n",
      "163:\ttotal: 37.1s\tremaining: 8.13s\n",
      "164:\ttotal: 37.3s\tremaining: 7.91s\n",
      "165:\ttotal: 37.5s\tremaining: 7.68s\n",
      "166:\ttotal: 37.7s\tremaining: 7.45s\n",
      "167:\ttotal: 37.9s\tremaining: 7.22s\n",
      "168:\ttotal: 38.1s\tremaining: 6.99s\n",
      "169:\ttotal: 38.3s\tremaining: 6.76s\n",
      "170:\ttotal: 38.6s\tremaining: 6.54s\n",
      "171:\ttotal: 38.8s\tremaining: 6.31s\n",
      "172:\ttotal: 39s\tremaining: 6.08s\n",
      "173:\ttotal: 39.2s\tremaining: 5.86s\n",
      "174:\ttotal: 39.4s\tremaining: 5.63s\n",
      "175:\ttotal: 39.7s\tremaining: 5.41s\n",
      "176:\ttotal: 39.9s\tremaining: 5.19s\n",
      "177:\ttotal: 40.2s\tremaining: 4.96s\n",
      "178:\ttotal: 40.4s\tremaining: 4.74s\n",
      "179:\ttotal: 40.6s\tremaining: 4.51s\n",
      "180:\ttotal: 40.8s\tremaining: 4.29s\n",
      "181:\ttotal: 41s\tremaining: 4.06s\n",
      "182:\ttotal: 41.3s\tremaining: 3.83s\n",
      "183:\ttotal: 41.5s\tremaining: 3.61s\n",
      "184:\ttotal: 41.7s\tremaining: 3.38s\n",
      "185:\ttotal: 41.9s\tremaining: 3.15s\n",
      "186:\ttotal: 42.2s\tremaining: 2.93s\n",
      "187:\ttotal: 42.4s\tremaining: 2.71s\n",
      "188:\ttotal: 42.6s\tremaining: 2.48s\n",
      "189:\ttotal: 42.8s\tremaining: 2.25s\n",
      "190:\ttotal: 43.1s\tremaining: 2.03s\n",
      "191:\ttotal: 43.3s\tremaining: 1.8s\n",
      "192:\ttotal: 43.5s\tremaining: 1.58s\n",
      "193:\ttotal: 43.7s\tremaining: 1.35s\n",
      "194:\ttotal: 44s\tremaining: 1.13s\n",
      "195:\ttotal: 44.2s\tremaining: 903ms\n",
      "196:\ttotal: 44.5s\tremaining: 678ms\n",
      "197:\ttotal: 44.8s\tremaining: 452ms\n",
      "198:\ttotal: 45s\tremaining: 226ms\n",
      "199:\ttotal: 45.2s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "#xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "cb_oof_train, cb_oof_test = get_oof(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET-CV: 0.26204598466138296\n",
      "RF-CV: 0.2617941143339201\n",
      "RF-CV: 0.327318699834669\n"
     ]
    }
   ],
   "source": [
    "#print(\"XG-CV: {}\".format(sqrt(mean_squared_error(y_train, xg_oof_train))))\n",
    "print(\"ET-CV: {}\".format(sqrt(mean_squared_error(y_train, et_oof_train))))\n",
    "print(\"RF-CV: {}\".format(sqrt(mean_squared_error(y_train, rf_oof_train))))\n",
    "print(\"RF-CV: {}\".format(sqrt(mean_squared_error(y_train, cb_oof_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 3),(48744, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate((et_oof_train, rf_oof_train, cb_oof_train), axis=1)\n",
    "x_test = np.concatenate((et_oof_test, rf_oof_test, cb_oof_test), axis=1)\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 546),(48744, 545)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.concat([x_train,x_train_first],axis=1)\n",
    "x_test = pd.concat([x_test,x_test_first],axis=1)\n",
    "x_train_second = pd.concat([x_train,train_ids],axis=1)\n",
    "x_test_second = pd.concat([x_test,test_ids],axis=1)\n",
    "# TARGET列を再びくっつける\n",
    "x_train_second['TARGET'] = y_train\n",
    "print(\"{},{}\".format(x_train_second.shape, x_test_second.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', boosting_type='goss',\n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 544)\n",
      "Testing Data Shape:  (48744, 544)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.778964\ttrain's auc: 0.825009\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid's auc: 0.779588\ttrain's auc: 0.804727\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.782136\ttrain's auc: 0.824278\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.782173\ttrain's auc: 0.825158\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.774097\ttrain's auc: 0.826585\n",
      "[400]\tvalid's auc: 0.774454\ttrain's auc: 0.862687\n",
      "Early stopping, best iteration is:\n",
      "[410]\tvalid's auc: 0.774539\ttrain's auc: 0.864175\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.779548\ttrain's auc: 0.825415\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid's auc: 0.779752\ttrain's auc: 0.816823\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.779857\ttrain's auc: 0.824982\n",
      "[400]\tvalid's auc: 0.780066\ttrain's auc: 0.860896\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid's auc: 0.78022\ttrain's auc: 0.857574\n"
     ]
    }
   ],
   "source": [
    "submission, feature_importances, metrics = model(x_train_second,x_test_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.804727</td>\n",
       "      <td>0.779588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.825158</td>\n",
       "      <td>0.782173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.864175</td>\n",
       "      <td>0.774539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.816823</td>\n",
       "      <td>0.779752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.857574</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>overall</td>\n",
       "      <td>0.833691</td>\n",
       "      <td>0.778890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fold     train     valid\n",
       "0        0  0.804727  0.779588\n",
       "1        1  0.825158  0.782173\n",
       "2        2  0.864175  0.774539\n",
       "3        3  0.816823  0.779752\n",
       "4        4  0.857574  0.780220\n",
       "5  overall  0.833691  0.778890"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_stacking_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances_sorted = plot_feature_importances(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング・テストデータの出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('m_train.csv', index = False)\n",
    "test.to_csv('m_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imp.to_csv('m_train_imp.csv', index = False)\n",
    "test_imp.to_csv('m_test_imp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ensemble = submission.copy().drop(['TARGET'],axis=1)\n",
    "submission_ensemble['TARGET'] = (submission['TARGET'] + x_train_first['et']+ x_train_first['rf'])/3\n",
    "submission_ensemble['SK_ID_CURR']\n",
    "submission_ensemble.to_csv('submission_ensemble.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
